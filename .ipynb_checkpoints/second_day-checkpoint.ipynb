{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3113786b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>An Interesting Title</h1>\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def gettitle(url):\n",
    "    try:\n",
    "        html = urlopen(url)\n",
    "        \n",
    "    except HTTPError as e:\n",
    "        return None\n",
    "    try:\n",
    "        bsobj = BeautifulSoup(html.read())\n",
    "        title = bsobj.body.h1\n",
    "        \n",
    "    except AttributeError as e:\n",
    "        return None\n",
    "    \n",
    "    return title\n",
    "\n",
    "title = gettitle(\"http://www.pythonscraping.com/pages/page1.html\")\n",
    "\n",
    "if title == None:\n",
    "    print('Title could not found')\n",
    "    \n",
    "else:\n",
    "    print(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb217f97",
   "metadata": {},
   "source": [
    "# 复杂HTML解析\n",
    "\n",
    "## 不是一直都要用锤子\n",
    "\n",
    "不要直接用几行代码来提取内容\n",
    "\n",
    "HTML解析过程：\n",
    "·寻找“打印此页”的链接，或者看看网站有没有HTML样式更友好的移动版（把请求头设置成处于移动设备的状态，然后接受网站的移动版）\n",
    "·寻找隐藏在Javascript文件里的信息。可能要查看网站加载的JavaScript文件\n",
    "·网站的标题往往可以从网页的URL链接里获取\n",
    "·看看是否还有其他的数据源\n",
    "\n",
    "## 再端一碗beautifulsoup\n",
    "\n",
    "css\n",
    "先将抓取的HTML文件转化为BeautifulSoup对象\n",
    "1、findAll函数\n",
    "\n",
    "obj.findAll()实现原理：\n",
    "bsobj.tagName只能获取页面中的第一个指定的标签\n",
    "bsobj.findAll(tagName,tagAttributes)可以获取页面所有的指定的标签，而不再是第一个了。（attribute：动词：把···归因于。名词：属性、性质）\n",
    "\n",
    "遍历整个列表，然后对列表中的某个元素调用get_text()方法，就可以将标签中的内容分开显示了\n",
    "    get_text()会把正在处理的HTML文档中所有标签都删除，然后返回一个只包含文本的字符串。一般在处理的最后才使用该方法去掉标签\n",
    "    \n",
    "### find()  and   findAll()\n",
    "\n",
    "两个标签的定义：\n",
    "findAll(tag,attributes,recursive,text,limit,keywords)\n",
    "find(tag,attributes,recursive,text,keywords)\n",
    "\n",
    "返回文档的所有标题标签：\n",
    "findAll({'h1','h2','h3','h4'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0129ab44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<h1>War and Peace</h1>]\n"
     ]
    }
   ],
   "source": [
    "html_1 = urlopen(\"http://pythonscraping.com/pages/warandpeace.html\")\n",
    "\n",
    "bsobj_1 = BeautifulSoup(html_1)\n",
    "\n",
    "name_list = bsobj_1.findAll('span',{'class':'green'})\n",
    "dialogues = bsobj_1.findAll('span',{'class':'red'})\n",
    "title = bsobj_1.findAll('h1')\n",
    "\n",
    "#for name in name_list:\n",
    " #   print(name.get_text())\n",
    "    \n",
    "#for dialogue in dialogues:\n",
    " #   print(dialogue)\n",
    "\n",
    "print(title)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f0c8ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
